{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook fetches the data from ```build_csv_postgres.ipynb``` file that was uploaded to the Azure Postgres database, and converts it back to a CSV. If you wish, you can skip this notebook and download the data manually from Postgres. \n",
    "\n",
    "This notebook was created to gain practice with using GraphQL and act as a template for further development in terms of fetching data from Postgres database\n",
    "\n",
    "### Input\n",
    "\n",
    "Ensure you have a ```.env``` file in the same directory as this notebook with 2 keys:\n",
    "\n",
    "1. *URL* - for the Hasura database link that hosts our data via Postgres\n",
    "2. *SECRET* - unique password string given by Hasura that allows us to establish connection with our database\n",
    "\n",
    "### Output\n",
    "\n",
    "This notebook will output the Postgres database content as a single CSV file, in the ```output``` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gql import gql, Client\n",
    "from gql.transport.aiohttp import AIOHTTPTransport\n",
    "from gql.transport.exceptions import TransportQueryError\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import asyncio\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the keys from the environment file\n",
    "\n",
    "url = os.getenv('URL')\n",
    "secret = os.getenv('SECRET')\n",
    "\n",
    "# Send connection request to the Hasura database using a GraphQL client\n",
    "\n",
    "transport = AIOHTTPTransport(url=url, headers={\n",
    "    'x-hasura-admin-secret': secret,\n",
    "    'content-type': 'application/json'\n",
    "})\n",
    "\n",
    "gql_client = Client(transport=transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching started: <Thread(Thread-3 (run), started 5964)>\n",
      "Fetching ended: <Thread(Thread-3 (run), started 5964)>\n"
     ]
    }
   ],
   "source": [
    "# Global data variable will hold the Postgres database content and will be outputted as CSV in the end\n",
    "\n",
    "global data\n",
    "\n",
    "data = None\n",
    "\n",
    "# Asynchronous function required as the GraphQL queries are executed asynchronously\n",
    "\n",
    "async def fetch_queries():\n",
    "\n",
    "    global data\n",
    "    print('Fetching started:', threading.current_thread())\n",
    "\n",
    "    # Execute GraphQL queries to retrieve all house sale and tax assessment information\n",
    "    # If we try to fetch all of the approx. 47k rows from the Postgres database, the result will be too large and result in an error\n",
    "    # To avoid this, we only request data of 1000 rows per query and append its result to our dataframe\n",
    "\n",
    "    try:\n",
    "\n",
    "      # Total rows: 47385, if going at increments of 1000 rows, then it takes 48 loops\n",
    "\n",
    "      for row_limit in range(1, 49):\n",
    "\n",
    "          # Use double brackets to store them as part of the actual string when using f-strings\n",
    "\n",
    "          query = gql(\n",
    "              f\"\"\"\n",
    "              query MyQuery {{\n",
    "                  RealEstateUnits(where: {{ id: {{ _gte: \"{ (row_limit-1)*1000 }\" , _lte: \"{row_limit*1000}\" }} , PropertyType: {{_eq: \"house\"}} }}) {{\n",
    "                      PropertyDetails\n",
    "                      PropertyType\n",
    "                  }}\n",
    "              }}\n",
    "              \"\"\"\n",
    "          )\n",
    "\n",
    "          # Send query for execution\n",
    "\n",
    "          result = await gql_client.execute_async(query)\n",
    "\n",
    "          # Convert the resulting JSON string into a Pandas dataframe, and append it to our global data variable\n",
    "\n",
    "          json_str = json.dumps(result)\n",
    "          json_obj = json.loads(json_str)\n",
    "\n",
    "          data = pd.concat([data, pd.json_normalize(json_obj['RealEstateUnits'])], ignore_index=True)      \n",
    "\n",
    "\n",
    "    except TransportQueryError as err:\n",
    "      print(f\"Error: {err}\")\n",
    "      sys.exit(1)\n",
    "\n",
    "\n",
    "    print('Fetching ended:', threading.current_thread())\n",
    "\n",
    "\n",
    "# Since we are dealing with asynchronous functions, we must wait for the GraphQL query to finish before adding its content to the dataframe\n",
    "# Using Threads help us achieve this, otherwise Python Coroutine object is returned \n",
    "\n",
    "thread = threading.Thread( target=asyncio.run, args=(fetch_queries(),) )\n",
    "thread.start()\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arshb\\AppData\\Local\\Temp\\ipykernel_12024\\1468991257.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data.columns = data.columns.str.replace(\"PropertyDetails.\", \"\")\n"
     ]
    }
   ],
   "source": [
    "# Change the dataframe column names to their original format and fill missing values as NaN \n",
    "\n",
    "data.columns = data.columns.str.replace(\"PropertyDetails.\", \"\")\n",
    "data = data.fillna(value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataframe as CSV file\n",
    "\n",
    "data.to_csv('../datasets/output/fetch_postgres.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f65a7ea2c87698a8bad8c81566a0e37199fcfdf607b6d5eb2dce35518d337549"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
